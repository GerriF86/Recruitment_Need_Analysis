{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Capstone\\your_envs_directory\\mlenv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chatgroq'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19296\\250077874.py\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdotenv\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_dotenv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mchatgroq\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mChatGroq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Load environment variables (e.g., API keys for Llama RAG)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'chatgroq'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from chatgroq import ChatGroq\n",
    "\n",
    "# Load environment variables (e.g., API keys for Llama RAG)\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-8b-8192\",\n",
    "    temperature=0, \n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Job Description Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = pd.read_json(\"data/json/salaries.json\", lines=True)\n",
    "resumes = pd.read_json(\"data/json/Entity Recognition in Resumes.json\", lines=True)\n",
    "it_jobs = pd.read_json(\"data/json/IT Job Desc Annotated Detailed.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Step 1: Initialization\n",
    "\n",
    "class JobDescriptionGenerator:\n",
    "    def __init__(self):\n",
    "        # Initialize data with default values\n",
    "        self.data = {\n",
    "            \"Position\": \"N/A\",\n",
    "            \"Specialization\": \"N/A\",\n",
    "            \"Work Model\": \"N/A\",\n",
    "            \"Remote Location\": \"N/A\",\n",
    "            \"Remote Timezone\": \"N/A\",\n",
    "            \"Technical Equipment\": \"N/A\",\n",
    "            \"Remote Percentage\": \"N/A\",\n",
    "            \"BI Tools\": \"N/A\",\n",
    "            \"Required Tools\": \"N/A\",\n",
    "            \"Visualization Tools\": \"N/A\",\n",
    "            \"Statistical Methods\": \"N/A\",\n",
    "            \"Big Data Tools\": \"N/A\",\n",
    "            \"Experience Level\": \"N/A\",\n",
    "            \"Leadership Skills\": \"None\",\n",
    "            \"Educational Requirements\": \"None\",\n",
    "            \"Project Leadership\": \"No\",\n",
    "            \"Compensation\": \"N/A\",\n",
    "            \"Home Office Allowance\": \"None\",\n",
    "            \"Remote Benefits\": \"None\",\n",
    "            \"Additional Benefits\": \"None\"\n",
    "        }\n",
    "        # Load pre-trained model for embedding generation\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        # Initialize FAISS index for similarity search\n",
    "        self.index = None\n",
    "        self.documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ## Step 2: Data Cleaning and Preprocessing\n",
    "def clean_and_preprocess_dataset(self, dataset_path):\n",
    "        # Load dataset\n",
    "        with open(dataset_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Filter records with missing job descriptions\n",
    "        filtered_data = [item for item in data if 'job_description' in item and item['job_description'].strip()]\n",
    "\n",
    "        # Extract and normalize job descriptions\n",
    "        job_descriptions = [item['job_description'].strip().lower() for item in filtered_data]\n",
    "\n",
    "        # Remove duplicates\n",
    "        unique_job_descriptions = list(set(job_descriptions))\n",
    "\n",
    "        # Preprocess text to remove special characters\n",
    "        processed_descriptions = [re.sub(r'[^a-zA-Z0-9\\s]', '', desc) for desc in unique_job_descriptions]\n",
    "\n",
    "        return processed_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ## Step 3: Loading Dataset and Building FAISS Index\n",
    "def load_dataset_and_build_index(self, dataset):\n",
    "        # Clean and preprocess dataset\n",
    "        print(\"Cleaning and preprocessing dataset...\")\n",
    "        job_descriptions = self.clean_and_preprocess_dataset(dataset)\n",
    "        self.documents = job_descriptions\n",
    "\n",
    "        # Create embeddings for job descriptions with progress report\n",
    "        print(\"Generating embeddings...\")\n",
    "        embeddings = []\n",
    "        for desc in tqdm(job_descriptions, desc=\"Embedding job descriptions\"):\n",
    "            embedding = self.model.encode(desc)\n",
    "            embeddings.append(embedding)\n",
    "        embeddings = np.array(embeddings)\n",
    "\n",
    "        # Create a FAISS index and add embeddings\n",
    "        print(\"Building FAISS index...\")\n",
    "        if embeddings.size > 0:\n",
    "            dimension = embeddings.shape[1]\n",
    "            self.index = faiss.IndexFlatL2(dimension)\n",
    "            self.index.add(embeddings)\n",
    "        else:\n",
    "            print(\"Error: No embeddings found to build the FAISS index.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # ## Step 4: Finding Similar Job Descriptions\n",
    "def find_similar_jobs(self, query, k=3):\n",
    "        # Create embedding for the query\n",
    "        print(\"Generating embedding for the query...\")\n",
    "        query_embedding = self.model.encode([query])\n",
    "\n",
    "        # Search the FAISS index for similar job descriptions\n",
    "        print(\"Searching for similar job descriptions...\")\n",
    "        _, indices = self.index.search(np.array(query_embedding), k)\n",
    "\n",
    "        # Retrieve and return the top-k most similar job descriptions\n",
    "        return [self.documents[idx] for idx in indices[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ## Step 5: Interactive User Input\n",
    "def ask_question(self, question, options=None, multiple=False):\n",
    "        print(question)\n",
    "        if options:\n",
    "            for i, option in enumerate(options, 1):\n",
    "                print(f\"{i}. {option}\")\n",
    "            if multiple:\n",
    "                selected_options = input(\"Enter the numbers of all applicable options, separated by commas: \")\n",
    "                return [options[int(choice.strip()) - 1] for choice in selected_options.split(\",\")]\n",
    "            else:\n",
    "                while True:\n",
    "                    try:\n",
    "                        choice = int(input(\"Please choose an option: \")) - 1\n",
    "                        if 0 <= choice < len(options):\n",
    "                            return options[choice]\n",
    "                        else:\n",
    "                            print(\"Invalid choice. Please enter one of the displayed numbers.\")\n",
    "                    except ValueError:\n",
    "                        print(\"Invalid input. Please enter a number.\")\n",
    "        else:\n",
    "            # Use Llama RAG to get an enhanced response for a more complex question\n",
    "            user_input = input(\"Your question or query: \").strip()\n",
    "            response = llm.ask(user_input)\n",
    "            print(f\"AI Assistant Response: {response}\")\n",
    "            return response\n",
    "\n",
    "def ask_text_input(self, prompt):\n",
    "        return input(prompt).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ## Step 6: Collecting Job Information\n",
    "def collect_position_info(self):\n",
    "        position = self.ask_question(\"What position are you hiring for?\", [\"Data Scientist\", \"Data Analyst\"])\n",
    "        self.data[\"Position\"] = position\n",
    "\n",
    "        if position == \"Data Scientist\":\n",
    "            specialization = self.ask_question(\"Is there a specific focus for this role?\", [\"Machine Learning\", \"Statistics\", \"Big Data\"])\n",
    "            self.data[\"Specialization\"] = specialization\n",
    "\n",
    "            if specialization == \"Machine Learning\":\n",
    "                ml_focus = self.ask_question(\"Are there specific machine learning techniques required?\", [\"Deep Learning\", \"NLP\", \"Reinforcement Learning\"], multiple=True)\n",
    "                self.data[\"Machine Learning Focus\"] = ml_focus\n",
    "\n",
    "                if \"Deep Learning\" in ml_focus:\n",
    "                    self.data[\"Frameworks\"] = self.ask_question(\"Are there specific frameworks required?\", [\"TensorFlow\", \"Keras\", \"PyTorch\"], multiple=True)\n",
    "                if \"NLP\" in ml_focus:\n",
    "                    self.data[\"NLP Tools\"] = self.ask_question(\"Are there specific NLP libraries or tools that should be used?\", [\"spaCy\", \"Hugging Face\", \"NLTK\"], multiple=True)\n",
    "\n",
    "            elif specialization == \"Statistics\":\n",
    "                self.data[\"Statistical Methods\"] = self.ask_text_input(\"Which statistical methods are particularly important (e.g., regression analysis, ANOVA)?: \")\n",
    "\n",
    "            elif specialization == \"Big Data\":\n",
    "                self.data[\"Big Data Tools\"] = self.ask_text_input(\"Are there specific Big Data tools the candidate should be proficient with (e.g., Spark, Hadoop)?: \")\n",
    "\n",
    "            self.data[\"Tools\"] = self.ask_text_input(\"Please list any specific tools required for this role (e.g., Python, Java, Spark): \")\n",
    "\n",
    "        elif position == \"Data Analyst\":\n",
    "            focus_area = self.ask_question(\"What is the main focus for this role?\", [\"Statistical Analysis\", \"Business Intelligence\", \"Data Visualization\"])\n",
    "            self.data[\"Focus Area\"] = focus_area\n",
    "\n",
    "            if focus_area == \"Business Intelligence\":\n",
    "                self.data[\"BI Tools\"] = self.ask_question(\"Which BI tools should the candidate use?\", [\"PowerBI\", \"Tableau\", \"QlikView\"], multiple=True)\n",
    "                if \"PowerBI\" in self.data[\"BI Tools\"]:\n",
    "                    self.data[\"PowerBI Features\"] = self.ask_text_input(\"Are there specific PowerBI features the candidate should know (e.g., DAX, Power Query)?: \")\n",
    "\n",
    "            elif focus_area == \"Data Visualization\":\n",
    "                self.data[\"Visualization Tools\"] = self.ask_text_input(\"Which visualization tools are required (e.g., Matplotlib, D3.js, ggplot)?: \")\n",
    "\n",
    "            self.data[\"Tools\"] = self.ask_text_input(\"Please list any specific tools required for this role (e.g., Excel, PowerBI, SQL): \")\n",
    "\n",
    "def collect_work_model_info(self):\n",
    "        work_model = self.ask_question(\"Is the position On-Site, Remote, or Hybrid?\", [\"On-Site\", \"Remote\", \"Hybrid\"])\n",
    "        self.data[\"Work Model\"] = work_model\n",
    "\n",
    "        if work_model == \"Remote\":\n",
    "            self.data[\"Remote Location\"] = self.ask_question(\"Can the role be remote anywhere in Germany, EU-wide, or globally?\", [\"Germany\", \"EU-wide\", \"Worldwide\"])\n",
    "            self.data[\"Remote Timezone\"] = self.ask_question(\"Are there timezone or work hour requirements?\", [\"No specific requirements\", \"CET timezone preferred\", \"Fixed working hours required\"])\n",
    "            self.data[\"Technical Equipment\"] = self.ask_question(\"Will technical equipment be provided for remote work?\", [\"Yes\", \"No\"])\n",
    "\n",
    "        elif work_model == \"Hybrid\":\n",
    "            self.data[\"Remote Percentage\"] = self.ask_question(\"What percentage of work is Remote vs. On-Site?\", [\"70% Remote / 30% On-Site\", \"50% Remote / 50% On-Site\"])\n",
    "\n",
    "def collect_qualifications_info(self):\n",
    "        experience_level = self.ask_question(\"What level of experience is required for this role?\", [\"Junior\", \"Mid-Level\", \"Senior\"])\n",
    "        self.data[\"Experience Level\"] = experience_level\n",
    "\n",
    "        if experience_level == \"Junior\":\n",
    "            self.data[\"Educational Requirements\"] = self.ask_text_input(\"Are there specific educational requirements (e.g., Bachelor's in Computer Science)?: \")\n",
    "\n",
    "        elif experience_level == \"Mid-Level\":\n",
    "            self.data[\"Project Experience\"] = self.ask_text_input(\"What project experience should a mid-level candidate have (e.g., data analysis projects, model training)?: \")\n",
    "\n",
    "        elif experience_level == \"Senior\":\n",
    "            self.data[\"Project Leadership\"] = self.ask_question(\"Is project leadership experience required?\", [\"Yes\", \"No\"])\n",
    "            if self.data[\"Project Leadership\"] == \"Yes\":\n",
    "                self.data[\"Leadership Skills\"] = self.ask_text_input(\"What leadership skills are particularly important (e.g., team leadership, strategic planning)?: \")\n",
    "\n",
    "def collect_compensation_info(self):\n",
    "        self.data[\"Compensation\"] = self.ask_question(\"What does the compensation package include?\", [\"Fixed salary\", \"Variable compensation\", \"Both\"])\n",
    "\n",
    "        remote_benefits = self.ask_question(\"Are there specific benefits for remote employees?\", [\"Yes\", \"No\"])\n",
    "        if remote_benefits == \"Yes\":\n",
    "            # Additional follow-up questions for remote benefits\n",
    "            benefits = []\n",
    "            health_benefits = self.ask_text_input(\"Specify any health benefits (e.g., health insurance, wellness programs): \")\n",
    "            if health_benefits:\n",
    "                benefits.append(f\"Health Benefits: {health_benefits}\")\n",
    "            \n",
    "            internet_stipend = self.ask_text_input(\"Specify if there's an internet stipend or reimbursement: \")\n",
    "            if internet_stipend:\n",
    "                benefits.append(f\"Internet Stipend: {internet_stipend}\")\n",
    "            \n",
    "            professional_dev = self.ask_text_input(\"Specify if there are professional development funds (e.g., training, courses): \")\n",
    "            if professional_dev:\n",
    "                benefits.append(f\"Professional Development: {professional_dev}\")\n",
    "            \n",
    "            equipment_allowance = self.ask_text_input(\"Specify any equipment allowance for remote work: \")\n",
    "            if equipment_allowance:\n",
    "                benefits.append(f\"Equipment Allowance: {equipment_allowance}\")\n",
    "                \n",
    "            # Add gathered remote benefits to data\n",
    "            self.data[\"Remote Benefits\"] = \", \".join(benefits)\n",
    "\n",
    "            # Allowance follow-up question\n",
    "            periodicity = self.ask_question(\"Is the home office allowance provided monthly or yearly?\", [\"Monthly\", \"Yearly\"])\n",
    "            amount = self.ask_text_input(f\"Enter the {periodicity.lower()} allowance amount (e.g., 50 Euro): \")\n",
    "            self.data[\"Home Office Allowance\"] = f\"{periodicity} {amount}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ## Step 7: Generating Job Description\n",
    "def generate_job_description(self):\n",
    "        description = f\"\"\"\n",
    "        Position: {self.data[\"Position\"]}\n",
    "        Specialization: {self.data[\"Specialization\"]}\n",
    "        Work Model: {self.data[\"Work Model\"]}\n",
    "        Remote Location: {self.data[\"Remote Location\"]}\n",
    "        Remote Timezone: {self.data[\"Remote Timezone\"]}\n",
    "        Technical Equipment: {self.data[\"Technical Equipment\"]}\n",
    "        Remote Percentage: {self.data[\"Remote Percentage\"]}\n",
    "        BI Tools: {self.data[\"BI Tools\"]}\n",
    "        Required Tools: {self.data[\"Tools\"]}\n",
    "        Visualization Tools: {self.data[\"Visualization Tools\"]}\n",
    "        Statistical Methods: {self.data[\"Statistical Methods\"]}\n",
    "        Big Data Tools: {self.data[\"Big Data Tools\"]}\n",
    "        Experience Level: {self.data[\"Experience Level\"]}\n",
    "        Leadership Skills: {self.data[\"Leadership Skills\"]}\n",
    "        Educational Requirements: {self.data[\"Educational Requirements\"]}\n",
    "        Project Leadership: {self.data[\"Project Leadership\"]}\n",
    "        Compensation: {self.data[\"Compensation\"]}\n",
    "        Home Office Allowance: {self.data[\"Home Office Allowance\"]}\n",
    "        Remote Benefits: {self.data[\"Remote Benefits\"]}\n",
    "        Additional Benefits: {self.data[\"Additional Benefits\"]}\n",
    "        \"\"\"\n",
    "        print(\"\\n--- Generated Job Description ---\")\n",
    "        print(description.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Create an instance of the JobDescriptionGenerator\n",
    "    generator = JobDescriptionGenerator()\n",
    "\n",
    "    # Print all available methods to check if the class is properly defined\n",
    "    print(dir(generator))  # This will list all attributes and methods of the object\n",
    "\n",
    "    # Load Dataset and Build Index\n",
    "    generator.load_dataset_and_build_index(it_jobs)\n",
    "\n",
    "    # Run Job Description Generator\n",
    "    generator.run()\n",
    "\n",
    "    # Find Similar Job Descriptions\n",
    "    query = input(\"Enter a job role or description to find similar roles: \")\n",
    "    similar_jobs = generator.find_similar_jobs(query)\n",
    "    print(\"\\n--- Similar Job Descriptions ---\")\n",
    "    for job in similar_jobs:\n",
    "        print(job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ### Step 9: Load Dataset and Build Index\n",
    "generator = JobDescriptionGenerator()\n",
    "generator.load_dataset_and_build_index(it_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ### Step 10: Run Job Description Generator\n",
    "generator.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ### Step 11: Find Similar Job Descriptions\n",
    "query = input(\"Enter a job role or description to find similar roles: \")\n",
    "similar_jobs = generator.find_similar_jobs(query)\n",
    "print(\"\\n--- Similar Job Descriptions ---\")\n",
    "for job in similar_jobs:\n",
    "        print(job)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
