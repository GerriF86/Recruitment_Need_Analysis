{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced NLP Workbook for Recruitment Chatbot with Advanced Feature Engineering, State Machine, Sentiment Analysis, Personalization and Graph Database Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at C:\\Users\\gerri\\.conda\\envs\\capstone:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "ace-tools                 0.0                      pypi_0    pypi\n",
      "aiohappyeyeballs          2.4.3              pyhd8ed1ab_0    conda-forge\n",
      "aiohttp                   3.10.10         py310h38315fa_0    conda-forge\n",
      "aiosignal                 1.3.1              pyhd8ed1ab_0    conda-forge\n",
      "altair                    5.4.1              pyhd8ed1ab_1    conda-forge\n",
      "annotated-types           0.7.0              pyhd8ed1ab_0    conda-forge\n",
      "anyio                     4.6.2.post1        pyhd8ed1ab_0    conda-forge\n",
      "arrow-cpp                 16.1.0               h7cd61ee_0  \n",
      "asttokens                 2.4.1              pyhd8ed1ab_0    conda-forge\n",
      "async-timeout             4.0.3              pyhd8ed1ab_0    conda-forge\n",
      "attrs                     24.2.0             pyh71513ae_0    conda-forge\n",
      "aws-c-auth                0.6.21               h1ab79aa_0    conda-forge\n",
      "aws-c-cal                 0.5.20               h4b5e85a_3    conda-forge\n",
      "aws-c-common              0.8.5                hcfcfb64_0    conda-forge\n",
      "aws-c-compression         0.2.16               h3dc32ea_0    conda-forge\n",
      "aws-c-event-stream        0.2.15              hd4acc35_11    conda-forge\n",
      "aws-c-http                0.6.27               h844ee93_3    conda-forge\n",
      "aws-c-io                  0.13.11              hea55e33_2    conda-forge\n",
      "aws-c-mqtt                0.7.13               h9ca50f7_9    conda-forge\n",
      "aws-c-s3                  0.2.1                hcdbbf7e_0    conda-forge\n",
      "aws-c-sdkutils            0.1.7                h3dc32ea_0    conda-forge\n",
      "aws-checksums             0.1.13               h3dc32ea_5    conda-forge\n",
      "aws-crt-cpp               0.18.16              h6d7d590_2    conda-forge\n",
      "aws-sdk-cpp               1.10.55              hd77b12b_0  \n",
      "beautifulsoup4            4.12.3                   pypi_0    pypi\n",
      "blas                      1.0                         mkl  \n",
      "blinker                   1.8.2              pyhd8ed1ab_0    conda-forge\n",
      "boost-cpp                 1.78.0               h5b4e17d_0    conda-forge\n",
      "brotli                    1.0.9                hcfcfb64_9    conda-forge\n",
      "brotli-bin                1.0.9                hcfcfb64_9    conda-forge\n",
      "brotli-python             1.0.9           py310hd77b12b_8  \n",
      "bzip2                     1.0.8                h2bbff1b_6  \n",
      "c-ares                    1.34.2               h2466b09_0    conda-forge\n",
      "ca-certificates           2024.9.24            haa95532_0  \n",
      "cachetools                5.5.0              pyhd8ed1ab_0    conda-forge\n",
      "certifi                   2024.8.30          pyhd8ed1ab_0    conda-forge\n",
      "charset-normalizer        3.3.2              pyhd3eb1b0_0  \n",
      "click                     8.1.7           win_pyh7428d3b_0    conda-forge\n",
      "cloudpickle               3.1.0                    pypi_0    pypi\n",
      "colorama                  0.4.6              pyhd8ed1ab_0    conda-forge\n",
      "comm                      0.2.2              pyhd8ed1ab_0    conda-forge\n",
      "contourpy                 1.3.0           py310hc19bc0b_2    conda-forge\n",
      "cpuonly                   2.0                           0    pytorch\n",
      "cpython                   3.10.15         py310hd8ed1ab_2    conda-forge\n",
      "cycler                    0.12.1             pyhd8ed1ab_0    conda-forge\n",
      "dataclasses-json          0.6.7                    pypi_0    pypi\n",
      "datasets                  3.0.2              pyhd8ed1ab_0    conda-forge\n",
      "debugpy                   1.8.7           py310h9e98ed7_0    conda-forge\n",
      "decorator                 5.1.1              pyhd8ed1ab_0    conda-forge\n",
      "defusedxml                0.7.1                    pypi_0    pypi\n",
      "deprecated                1.2.14                   pypi_0    pypi\n",
      "dill                      0.3.8              pyhd8ed1ab_0    conda-forge\n",
      "dirtyjson                 1.0.8                    pypi_0    pypi\n",
      "distro                    1.9.0                    pypi_0    pypi\n",
      "exceptiongroup            1.2.2              pyhd8ed1ab_0    conda-forge\n",
      "executing                 2.1.0              pyhd8ed1ab_0    conda-forge\n",
      "faiss                     1.8.0           py310h08dd226_1_cpu    conda-forge\n",
      "faiss-cpu                 1.9.0                    pypi_0    pypi\n",
      "filelock                  3.13.1          py310haa95532_0  \n",
      "flask                     3.0.3              pyhd8ed1ab_0    conda-forge\n",
      "fonttools                 4.54.1          py310h38315fa_1    conda-forge\n",
      "fpdf                      1.7.2                    pypi_0    pypi\n",
      "fpdf2                     2.8.1                    pypi_0    pypi\n",
      "freetype                  2.12.1               ha860e81_0  \n",
      "frozenlist                1.5.0           py310ha8f682b_0    conda-forge\n",
      "fsspec                    2024.9.0           pyhff2d567_0    conda-forge\n",
      "gensim                    4.3.3           py310hbbd805c_0    conda-forge\n",
      "gflags                    2.2.2             he0c23c2_1005    conda-forge\n",
      "giflib                    5.2.2                h7edc060_0  \n",
      "gitdb                     4.0.11             pyhd8ed1ab_0    conda-forge\n",
      "gitpython                 3.1.43             pyhd8ed1ab_0    conda-forge\n",
      "glog                      0.5.0                h4797de2_0    conda-forge\n",
      "gmpy2                     2.1.2           py310h7f96b67_0  \n",
      "greenlet                  3.1.1           py310h9e98ed7_0    conda-forge\n",
      "groq                      0.11.0                   pypi_0    pypi\n",
      "h11                       0.14.0             pyhd8ed1ab_0    conda-forge\n",
      "h2                        4.1.0              pyhd8ed1ab_0    conda-forge\n",
      "hpack                     4.0.0              pyh9f0ad1d_0    conda-forge\n",
      "httpcore                  1.0.6              pyhd8ed1ab_0    conda-forge\n",
      "httpx                     0.27.2             pyhd8ed1ab_0    conda-forge\n",
      "httpx-sse                 0.4.0                    pypi_0    pypi\n",
      "huggingface_hub           0.26.2             pyh0610db2_0    conda-forge\n",
      "hyperframe                6.0.1              pyhd8ed1ab_0    conda-forge\n",
      "icu                       73.2                 h63175ca_0    conda-forge\n",
      "idna                      3.7             py310haa95532_0  \n",
      "importlib-metadata        7.2.1              pyha770c72_0    conda-forge\n",
      "importlib_resources       6.4.5              pyhd8ed1ab_0    conda-forge\n",
      "intel-openmp              2023.1.0         h59b6b97_46320  \n",
      "ipykernel                 6.29.5             pyh4bbf305_0    conda-forge\n",
      "ipython                   8.29.0             pyh7428d3b_0    conda-forge\n",
      "ipywidgets                8.1.5              pyhd8ed1ab_0    conda-forge\n",
      "itsdangerous              2.2.0              pyhd8ed1ab_0    conda-forge\n",
      "jedi                      0.19.1             pyhd8ed1ab_0    conda-forge\n",
      "jinja2                    3.1.4           py310haa95532_0  \n",
      "jiter                     0.7.0                    pypi_0    pypi\n",
      "joblib                    1.4.2              pyhd8ed1ab_0    conda-forge\n",
      "jpeg                      9e                   h827c3e9_3  \n",
      "jsonpatch                 1.33               pyhd8ed1ab_0    conda-forge\n",
      "jsonpointer               3.0.0           py310h5588dad_1    conda-forge\n",
      "jsonschema                4.23.0             pyhd8ed1ab_0    conda-forge\n",
      "jsonschema-specifications 2024.10.1          pyhd8ed1ab_0    conda-forge\n",
      "jupyter_client            8.6.3              pyhd8ed1ab_0    conda-forge\n",
      "jupyter_core              5.7.2              pyh5737063_1    conda-forge\n",
      "jupyterlab_widgets        3.0.13             pyhd8ed1ab_0    conda-forge\n",
      "kiwisolver                1.4.7           py310hc19bc0b_0    conda-forge\n",
      "krb5                      1.20.1               heb0366b_0    conda-forge\n",
      "langchain                 0.3.6                    pypi_0    pypi\n",
      "langchain-community       0.3.5                    pypi_0    pypi\n",
      "langchain-core            0.3.15             pyhd8ed1ab_0    conda-forge\n",
      "langchain-groq            0.2.1                    pypi_0    pypi\n",
      "langchain-text-splitters  0.3.1                    pypi_0    pypi\n",
      "langsmith                 0.1.139                  pypi_0    pypi\n",
      "lcms2                     2.12                 h83e58a3_0  \n",
      "lerc                      3.0                  hd77b12b_0  \n",
      "libabseil                 20240116.2      cxx17_he0c23c2_1    conda-forge\n",
      "libblas                   3.9.0           1_h8933c1f_netlib    conda-forge\n",
      "libbrotlicommon           1.0.9                hcfcfb64_9    conda-forge\n",
      "libbrotlidec              1.0.9                hcfcfb64_9    conda-forge\n",
      "libbrotlienc              1.0.9                hcfcfb64_9    conda-forge\n",
      "libcblas                  3.9.0           5_hd5c7e75_netlib    conda-forge\n",
      "libclang                  14.0.6          default_hb5a9fac_1  \n",
      "libclang13                14.0.6          default_h8e68704_1  \n",
      "libcurl                   8.9.1                h0416ee5_0  \n",
      "libdeflate                1.17                 h2bbff1b_1  \n",
      "libevent                  2.1.12               h3671451_1    conda-forge\n",
      "libfaiss                  1.8.0            hb15a273_1_cpu    conda-forge\n",
      "libffi                    3.4.4                hd77b12b_1  \n",
      "libgrpc                   1.62.2               hf25190f_0  \n",
      "libjpeg-turbo             2.0.0                h196d8e1_0  \n",
      "liblapack                 3.9.0           5_hd5c7e75_netlib    conda-forge\n",
      "libpng                    1.6.39               h8cc25b3_0  \n",
      "libpq                     12.17                h906ac69_0  \n",
      "libprotobuf               4.25.3               hf2fb9eb_0  \n",
      "libsodium                 1.0.18               h8d14728_1    conda-forge\n",
      "libssh2                   1.10.0               h9a1e1f7_2    conda-forge\n",
      "libthrift                 0.15.0               h4364b78_2  \n",
      "libtiff                   4.5.1                hd77b12b_0  \n",
      "libuv                     1.48.0               h827c3e9_0  \n",
      "libwebp                   1.3.2                hbc33d0d_0  \n",
      "libwebp-base              1.3.2                h3d04722_1  \n",
      "llama-cloud               0.1.4                    pypi_0    pypi\n",
      "llama-index               0.11.22                  pypi_0    pypi\n",
      "llama-index-agent-openai  0.3.4                    pypi_0    pypi\n",
      "llama-index-cli           0.3.1                    pypi_0    pypi\n",
      "llama-index-core          0.11.22                  pypi_0    pypi\n",
      "llama-index-embeddings-openai 0.2.5                    pypi_0    pypi\n",
      "llama-index-indices-managed-llama-cloud 0.4.0                    pypi_0    pypi\n",
      "llama-index-legacy        0.9.48.post3             pypi_0    pypi\n",
      "llama-index-llms-openai   0.2.16                   pypi_0    pypi\n",
      "llama-index-multi-modal-llms-openai 0.2.3                    pypi_0    pypi\n",
      "llama-index-program-openai 0.2.0                    pypi_0    pypi\n",
      "llama-index-question-gen-openai 0.2.0                    pypi_0    pypi\n",
      "llama-index-readers-file  0.2.2                    pypi_0    pypi\n",
      "llama-index-readers-llama-parse 0.3.0                    pypi_0    pypi\n",
      "llama-parse               0.5.13                   pypi_0    pypi\n",
      "llvmlite                  0.43.0                   pypi_0    pypi\n",
      "lz4-c                     1.9.4                h2bbff1b_1  \n",
      "m2w64-gcc-libgfortran     5.3.0                         6    conda-forge\n",
      "m2w64-gcc-libs            5.3.0                         7    conda-forge\n",
      "m2w64-gcc-libs-core       5.3.0                         7    conda-forge\n",
      "m2w64-gmp                 6.1.0                         2    conda-forge\n",
      "m2w64-libwinpthread-git   5.0.0.4634.697f757               2    conda-forge\n",
      "markdown-it-py            3.0.0              pyhd8ed1ab_0    conda-forge\n",
      "markupsafe                2.1.3           py310h2bbff1b_0  \n",
      "marshmallow               3.23.1                   pypi_0    pypi\n",
      "matplotlib                3.9.1           py310h5588dad_1    conda-forge\n",
      "matplotlib-base           3.9.1           py310h37e0a56_2    conda-forge\n",
      "matplotlib-inline         0.1.7              pyhd8ed1ab_0    conda-forge\n",
      "mdurl                     0.1.2              pyhd8ed1ab_0    conda-forge\n",
      "missingno                 0.5.2                    pypi_0    pypi\n",
      "mkl                       2023.1.0         h6b88ed4_46358  \n",
      "mkl-service               2.4.0           py310h2bbff1b_1  \n",
      "mkl_fft                   1.3.10          py310h827c3e9_0  \n",
      "mkl_random                1.2.7           py310hc64d2fc_0  \n",
      "mpc                       1.1.0                h7edee0f_1  \n",
      "mpfr                      4.0.2                h62dcd97_1  \n",
      "mpir                      3.0.0                hec2e145_1  \n",
      "mpmath                    1.3.0           py310haa95532_0  \n",
      "msys2-conda-epoch         20160418                      1    conda-forge\n",
      "multidict                 6.1.0           py310h38315fa_1    conda-forge\n",
      "multiprocess              0.70.16         py310ha8f682b_1    conda-forge\n",
      "munkres                   1.1.4              pyh9f0ad1d_0    conda-forge\n",
      "mypy-extensions           1.0.0                    pypi_0    pypi\n",
      "narwhals                  1.12.1             pyhd8ed1ab_0    conda-forge\n",
      "nest-asyncio              1.6.0              pyhd8ed1ab_0    conda-forge\n",
      "networkx                  3.2.1           py310haa95532_0  \n",
      "nltk                      3.9.1                    pypi_0    pypi\n",
      "numba                     0.60.0                   pypi_0    pypi\n",
      "numpy                     1.26.4          py310h055cbcc_0  \n",
      "numpy-base                1.26.4          py310h65a83cf_0  \n",
      "openai                    1.53.0                   pypi_0    pypi\n",
      "openjpeg                  2.5.2                hae555c5_0  \n",
      "openssl                   3.3.2                h2466b09_0    conda-forge\n",
      "orc                       2.0.1                hd8d391b_0  \n",
      "orjson                    3.10.10                  pypi_0    pypi\n",
      "packaging                 24.1               pyhd8ed1ab_0    conda-forge\n",
      "pandas                    2.2.3           py310hb4db72f_1    conda-forge\n",
      "parso                     0.8.4              pyhd8ed1ab_0    conda-forge\n",
      "patsy                     0.5.6              pyhd8ed1ab_0    conda-forge\n",
      "pickleshare               0.7.5                   py_1003    conda-forge\n",
      "pillow                    10.4.0          py310h827c3e9_0  \n",
      "pip                       24.2            py310haa95532_0  \n",
      "pkgutil-resolve-name      1.3.10             pyhd8ed1ab_1    conda-forge\n",
      "platformdirs              4.3.6              pyhd8ed1ab_0    conda-forge\n",
      "prompt-toolkit            3.0.48             pyha770c72_0    conda-forge\n",
      "propcache                 0.2.0           py310ha8f682b_2    conda-forge\n",
      "protobuf                  4.25.3          py310hb55946c_1    conda-forge\n",
      "psutil                    6.1.0           py310ha8f682b_0    conda-forge\n",
      "pure_eval                 0.2.3              pyhd8ed1ab_0    conda-forge\n",
      "pyarrow                   16.1.0          py310hc64d2fc_0  \n",
      "pydantic                  2.9.2              pyhd8ed1ab_0    conda-forge\n",
      "pydantic-core             2.23.4          py310hc226416_0    conda-forge\n",
      "pydantic-settings         2.6.1                    pypi_0    pypi\n",
      "pydeck                    0.8.0              pyhd8ed1ab_0    conda-forge\n",
      "pygments                  2.18.0             pyhd8ed1ab_0    conda-forge\n",
      "pyparsing                 3.2.0              pyhd8ed1ab_1    conda-forge\n",
      "pypdf                     4.3.1                    pypi_0    pypi\n",
      "pyqt                      5.15.4          py310h8a704f9_0    conda-forge\n",
      "pyqt5-sip                 12.9.0          py310h8a704f9_0    conda-forge\n",
      "pysocks                   1.7.1           py310haa95532_0  \n",
      "python                    3.10.15              h4607a30_1  \n",
      "python-dateutil           2.9.0              pyhd8ed1ab_0    conda-forge\n",
      "python-dotenv             1.0.1              pyhd8ed1ab_0    conda-forge\n",
      "python-tzdata             2024.2             pyhd8ed1ab_0    conda-forge\n",
      "python-xxhash             3.5.0           py310ha8f682b_1    conda-forge\n",
      "python_abi                3.10                    2_cp310    conda-forge\n",
      "pytorch                   2.5.1              py3.10_cpu_0    pytorch\n",
      "pytorch-mutex             1.0                         cpu    pytorch\n",
      "pytz                      2024.1             pyhd8ed1ab_0    conda-forge\n",
      "pywin32                   307             py310h9e98ed7_3    conda-forge\n",
      "pyyaml                    6.0.2           py310h827c3e9_0  \n",
      "pyzmq                     26.2.0          py310h656833d_1    conda-forge\n",
      "qhull                     2020.2               hc790b64_5    conda-forge\n",
      "qt-main                   5.15.2              h19c9488_10  \n",
      "re2                       2022.04.01           h0e60522_0    conda-forge\n",
      "referencing               0.35.1             pyhd8ed1ab_0    conda-forge\n",
      "regex                     2024.9.11       py310ha8f682b_0    conda-forge\n",
      "requests                  2.32.3             pyhd8ed1ab_0    conda-forge\n",
      "requests-toolbelt         1.0.0              pyhd8ed1ab_0    conda-forge\n",
      "rich                      13.9.3             pyhd8ed1ab_0    conda-forge\n",
      "rpds-py                   0.20.0          py310hc226416_1    conda-forge\n",
      "safetensors               0.4.5           py310hc226416_0    conda-forge\n",
      "scikit-learn              1.5.2           py310hf2a6c47_1    conda-forge\n",
      "scipy                     1.14.1          py310hbd0dde3_1    conda-forge\n",
      "seaborn                   0.13.2               hd8ed1ab_2    conda-forge\n",
      "seaborn-base              0.13.2             pyhd8ed1ab_2    conda-forge\n",
      "sentence-transformers     3.2.1                    pypi_0    pypi\n",
      "setuptools                75.1.0          py310haa95532_0  \n",
      "shap                      0.46.0                   pypi_0    pypi\n",
      "sip                       6.5.1           py310h8a704f9_2    conda-forge\n",
      "six                       1.16.0             pyh6c4a22f_0    conda-forge\n",
      "slicer                    0.0.8                    pypi_0    pypi\n",
      "smart_open                7.0.5              pyhd8ed1ab_1    conda-forge\n",
      "smmap                     5.0.0              pyhd8ed1ab_0    conda-forge\n",
      "snappy                    1.2.1                h23299a8_0    conda-forge\n",
      "sniffio                   1.3.1              pyhd8ed1ab_0    conda-forge\n",
      "soupsieve                 2.6                      pypi_0    pypi\n",
      "sqlalchemy                2.0.35                   pypi_0    pypi\n",
      "sqlite                    3.45.3               h2bbff1b_0  \n",
      "stack_data                0.6.2              pyhd8ed1ab_0    conda-forge\n",
      "statsmodels               0.14.4          py310hb0944cc_0    conda-forge\n",
      "streamlit                 1.39.0             pyhd8ed1ab_0    conda-forge\n",
      "striprtf                  0.0.26                   pypi_0    pypi\n",
      "sympy                     1.13.1                   pypi_0    pypi\n",
      "tbb                       2021.8.0             h59b6b97_0  \n",
      "tenacity                  8.5.0              pyhd8ed1ab_0    conda-forge\n",
      "threadpoolctl             3.5.0              pyhc1e730c_0    conda-forge\n",
      "tiktoken                  0.8.0                    pypi_0    pypi\n",
      "tk                        8.6.14               h0416ee5_0  \n",
      "tokenizers                0.20.1          py310hddca29c_0    conda-forge\n",
      "toml                      0.10.2             pyhd8ed1ab_0    conda-forge\n",
      "torchaudio                2.5.1                 py310_cpu    pytorch\n",
      "torchvision               0.20.1                py310_cpu    pytorch\n",
      "tornado                   6.4.1           py310ha8f682b_1    conda-forge\n",
      "tqdm                      4.66.6             pyhd8ed1ab_0    conda-forge\n",
      "traitlets                 5.14.3             pyhd8ed1ab_0    conda-forge\n",
      "transformers              4.46.1             pyhd8ed1ab_0    conda-forge\n",
      "transitions               0.9.2              pyhd8ed1ab_0    conda-forge\n",
      "typing-extensions         4.11.0          py310haa95532_0  \n",
      "typing-inspect            0.9.0                    pypi_0    pypi\n",
      "typing_extensions         4.11.0          py310haa95532_0  \n",
      "tzdata                    2024b                h04d1e81_0  \n",
      "tzlocal                   5.2             py310h5588dad_1    conda-forge\n",
      "ucrt                      10.0.22621.0         h57928b3_1    conda-forge\n",
      "unicodedata2              15.1.0          py310ha8f682b_1    conda-forge\n",
      "urllib3                   2.2.3           py310haa95532_0  \n",
      "utf8proc                  2.6.1                h2bbff1b_1  \n",
      "validators                0.34.0             pyhd8ed1ab_0    conda-forge\n",
      "vc                        14.40                h2eaa2aa_1  \n",
      "vc14_runtime              14.40.33810         hcc2c482_22    conda-forge\n",
      "vs2015_runtime            14.40.33810         h3bf8584_22    conda-forge\n",
      "watchdog                  5.0.3           py310h5588dad_0    conda-forge\n",
      "wcwidth                   0.2.13             pyhd8ed1ab_0    conda-forge\n",
      "werkzeug                  3.1.0              pyhd8ed1ab_0    conda-forge\n",
      "wheel                     0.44.0          py310haa95532_0  \n",
      "widgetsnbextension        4.0.13             pyhd8ed1ab_0    conda-forge\n",
      "win_inet_pton             1.1.0           py310haa95532_0  \n",
      "wordcloud                 1.9.3                    pypi_0    pypi\n",
      "wrapt                     1.16.0          py310ha8f682b_1    conda-forge\n",
      "xxhash                    0.8.2                hcfcfb64_0    conda-forge\n",
      "xz                        5.4.6                h8cc25b3_1  \n",
      "yaml                      0.2.5                he774522_0  \n",
      "yarl                      1.16.0          py310ha8f682b_0    conda-forge\n",
      "zeromq                    4.3.5                he0c23c2_3    conda-forge\n",
      "zipp                      3.20.2             pyhd8ed1ab_0    conda-forge\n",
      "zlib                      1.2.13               h8cc25b3_1  \n",
      "zstd                      1.5.6                h8880b57_0  \n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Importing Required Libraries\n",
    "\n",
    "We import necessary Python libraries for data manipulation, feature extraction, modeling, evaluation, and visualization.\n",
    "\n",
    "- **Numpy and Pandas** for data manipulation.\n",
    "- **Scikit-learn** for model building, feature extraction, and evaluation.\n",
    "- **VaderSentiment** for sentiment analysis.\n",
    "- **Matplotlib and Seaborn** for data visualization.\n",
    "- **Tqdm** for progress bars to monitor loops and training processes.\n",
    "- **Transitions** for implementing state machines to manage the conversation flow.\n",
    "- **Neo4j** for using graph databases for a flexible conversation flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Import Libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Load environment variables (e.g., API keys for Llama RAG)\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    given the information {information} about a vacancy I want you to create a professional job advertisement\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"information\"],\n",
    "    template=query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Set up Llama RAG\n",
    "class LlamaRAG:\n",
    "    def __init__(self, model_path):\n",
    "        \"\"\"\n",
    "        Initializes Retrieval-Augmented Generation model using Llama.\n",
    "        \"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.llm = LlamaCpp(model_path=self.model_path, api_key=groq_api_key)\n",
    "        self.service_context = ServiceContext.from_defaults(llm=self.llm)\n",
    "        self.index = self.build_index()\n",
    "\n",
    "    def build_index(self):\n",
    "        \"\"\"\n",
    "        Build the GPTVectorStoreIndex from documents in the provided 'data' folder.\n",
    "        \"\"\"\n",
    "        documents = SimpleDirectoryReader('F:\\Capstone\\Github Repo\\Recruitment_Need_Analysis_Wepapp_DS_Capstone\\data').load_data()\n",
    "        index = VectorStoreIndex.from_documents(documents, service_context=self.service_context)\n",
    "        return index\n",
    "\n",
    "    def query(self, user_input):\n",
    "        \"\"\"\n",
    "        Query the Llama model with user input to get a response.\n",
    "        \"\"\"\n",
    "        response = self.index.query(user_input)\n",
    "        return response.response\n",
    "\n",
    "# Initialize Llama RAG\n",
    "rag_model = LlamaRAG(model_path='./path/to/your/llama/model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Set up Llama RAG\n",
    "class LlamaRAG:\n",
    "    def __init__(self, model_path):\n",
    "        \"\"\"\n",
    "        Initializes Retrieval-Augmented Generation model using Llama.\n",
    "        \"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.llm = LlamaCpp(model_path=self.model_path)\n",
    "        self.service_context = ServiceContext.from_defaults(llm=self.llm)\n",
    "        self.index = self.build_index()\n",
    "\n",
    "    def build_index(self):\n",
    "        \"\"\"\n",
    "        Build the GPTSimpleVectorIndex from documents in the provided 'data' folder.\n",
    "        \"\"\"\n",
    "        documents = SimpleDirectoryReader('F:\\Capstone\\Github Repo\\Recruitment_Need_Analysis_Wepapp_DS_Capstone\\data').load_data()\n",
    "        index = GPTSimpleVectorIndex.from_documents(documents, service_context=self.service_context)\n",
    "        return index\n",
    "\n",
    "    def query(self, user_input):\n",
    "        \"\"\"\n",
    "        Query the Llama model with user input to get a response.\n",
    "        \"\"\"\n",
    "        response = self.index.query(user_input)\n",
    "        return response.response\n",
    "\n",
    "# Initialize Llama RAG\n",
    "rag_model = LlamaRAG(model_path='./path/to/your/llama/model.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Update Recruitment Bot Workflow\n",
    "class RecruitmentBot:\n",
    "    def __init__(self):\n",
    "        # State machine setup for managing bot conversation flow\n",
    "        self.states = ['initial', 'gathering_info', 'presenting_summary', 'done']\n",
    "        self.machine = Machine(model=se\n",
    "lf, states=self.states, initial='initial')\n",
    "        self.machine.add_transition(trigger='start_info_gathering', source='initial', dest='gathering_info')\n",
    "        self.machine.add_transition(trigger='complete_summary', source='gathering_info', dest='presenting_summary')\n",
    "        self.machine.add_transition(trigger='finish', source='presenting_summary', dest='done')\n",
    "\n",
    "    def ask_question(self, user_input):\n",
    "        \"\"\"\n",
    "        Uses OpenAI RAG to generate relevant questions for the role based on user responses.\n",
    "        \"\"\"\n",
    "        response = rag_model(user_input)\n",
    "        return response\n",
    "\n",
    "    def collect_input(self, user_input):\n",
    "        \"\"\"\n",
    "        Collect input from the user and update internal states, if needed.\n",
    "        \"\"\"\n",
    "        if self.state == 'gathering_info':\n",
    "            # Process input using RAG for enhanced responses\n",
    "            detailed_response = self.ask_question(user_input)\n",
    "            return detailed_response\n",
    "        elif self.state == 'presenting_summary':\n",
    "            # Summarize details collected\n",
    "            return \"Here is the summary of information gathered.\"  # Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Interaction with the Bot\n",
    "if __name__ == \"__main__\":\n",
    "    bot = RecruitmentBot()\n",
    "    bot.start_info_gathering()\n",
    "    \n",
    "    print(\"Welcome to the Recruitment Assistant!\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"quit\":\n",
    "            bot.finish()\n",
    "            break\n",
    "        # Collect input and respond using RAG\n",
    "        response = bot.collect_input(user_input)\n",
    "        print(f\"Bot: {response}\")\n",
    "\n",
    "# Step 6: Deployment and Fine-tuning\n",
    "# Deployment:\n",
    "# 1. Dockerize the application: Create a Dockerfile that contains all necessary dependencies for the bot, including Python, required libraries, and environment variables.\n",
    "# 2. Create a requirements.txt file to list all Python dependencies:\n",
    "#\n",
    "# transitions\n",
    "# langchain\n",
    "# dotenv\n",
    "# scikit-learn\n",
    "# faiss-cpu\n",
    "#\n",
    "# 3. Build the Docker image:\n",
    "#    docker build -t recruitment_bot .\n",
    "# 4. Run the bot in a container:\n",
    "#    docker run -p 8080:8080 recruitment_bot\n",
    "# 5. Deploy on a cloud service such as AWS, Azure, or Google Cloud Platform for scalability.\n",
    "#\n",
    "# Fine-Tuning:\n",
    "# 1. Optimize Retrieval Strategy:\n",
    "#    - Modify the FAISS document store to include more documents for richer context.\n",
    "#    - Adjust the indexing parameters in FAISS to balance between retrieval speed and accuracy.\n",
    "#\n",
    "# 2. Tune OpenAI Hyperparameters:\n",
    "#    - Experiment with model parameters such as temperature, max_tokens, and frequency_penalty to control the style and detail of responses.\n",
    "#\n",
    "# 3. Enhance NLP capabilities:\n",
    "#    - Use additional NLP techniques, such as Named Entity Recognition (NER), to better extract and understand user inputs.\n",
    "#\n",
    "# 4. Customization for Specific Roles:\n",
    "#    - Pre-train the model on documents related to specific industries (e.g., finance, healthcare) to provide more nuanced and role-specific responses.\n",
    "#\n",
    "# 5. Update Document Store:\n",
    "#    - Regularly update the FAISS document store with new job postings, company data, and industry insights to keep responses fresh and relevant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Loading, Merging, and Integrating New Datasets\n",
    "\n",
    "In this step, we merge various data sources (`sample_skills.csv`, `sample_job_summary.csv`, and `gd_rev_preprocessed.csv`) to form a unified dataset for further analysis. This helps provide a complete understanding of the job descriptions.\n",
    "\n",
    "- **Data Sources**: Skills, job summaries, and interview Q&A.\n",
    "- **Purpose**: To enrich the dataset with all possible information to produce insightful NLP analysis.\n",
    "- **Merging Strategy**: Merge on `job_title` to ensure that all related information is brought together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "gsearch_jobs = pd.read_csv('data/gsearch_jobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_jobs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_jobs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Data Cleaning and Preprocessing\n",
    "\n",
    "We clean text data to remove any unnecessary characters and prepare the dataset for NLP operations. This involves removing punctuation, converting text to lowercase, and combining key textual information into a single column for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'\\W+', ' ', text)  # Remove non-word characters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "# Apply text cleaning to relevant columns\n",
    "gsearch_jobs['description_clean'] = gsearch_jobs['description'].apply(lambda x: clean_text(str(x)))\n",
    "\n",
    "# Drop rows with missing descriptions\n",
    "gsearch_jobs.dropna(subset=['description_clean'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Advanced Feature Engineering\n",
    "\n",
    "#### Step 5.1: TF-IDF Vectorization\n",
    "\n",
    "We use **TF-IDF Vectorizer** to convert the textual data into numerical feature vectors that the model can process.\n",
    "\n",
    "- **Why TF-IDF**: It captures the importance of words in a document relative to the corpus, making it a powerful feature extraction technique for NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X = vectorizer.fit_transform(gsearch_jobs['description_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5.2: Polynomial Features and Standard Scaling\n",
    "\n",
    "- **Polynomial Features**: Increase the complexity of our features by generating interaction terms, which can improve model performance when relationships between features are non-linear.\n",
    "- **Standard Scaling**: Standardizes the features by removing the mean and scaling to unit variance, which is especially important for linear models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add polynomial features to increase feature complexity (Reduced degree to prevent memory issues)\n",
    "poly = PolynomialFeatures(degree=1, interaction_only=True, include_bias=False)\n",
    "X_poly = poly.fit_transform(X.toarray())\n",
    "\n",
    "# Min-Max Scaling to keep features non-negative\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5.3: Dimensionality Reduction\n",
    "\n",
    "We use **Truncated SVD** to reduce the dimensionality of the TF-IDF matrix. This helps reduce computational cost and overfitting while preserving essential information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Truncated SVD to reduce dimensionality\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)  # Reduce dimensions further to avoid overfitting\n",
    "X_reduced = svd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 6: Introducing State Machine for Conversation Flow Management\n",
    "\n",
    "We use a **State Machine** to define the conversation flow for guiding managers through the recruitment question generation process.\n",
    "\n",
    "#### Step 6.1: Defining States and Transitions\n",
    "\n",
    "- **States**: Represent parts of the conversation (e.g., Role Requirements, Company Environment, Compensation & Benefits).\n",
    "- **Transitions**: Define how the flow moves from one state to another based on the manager's response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transitions import Machine\n",
    "\n",
    "# Define states for the recruitment conversation flow\n",
    "states = ['role_requirements', 'company_environment', 'compensation_benefits', 'role_nuances', 'final_summary']\n",
    "\n",
    "# Define the state machine model\n",
    "class RecruitmentAssistant:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "# Create an instance of RecruitmentAssistant\n",
    "recruitment_assistant = RecruitmentAssistant(\"Assistant\")\n",
    "\n",
    "# Create a state machine with defined states and transitions\n",
    "machine = Machine(model=recruitment_assistant, states=states, initial='role_requirements')\n",
    "\n",
    "# Define state transitions based on manager inputs\n",
    "machine.add_transition(trigger='ask_company_environment', source='role_requirements', dest='company_environment')\n",
    "machine.add_transition(trigger='ask_compensation', source='company_environment', dest='compensation_benefits')\n",
    "machine.add_transition(trigger='ask_role_nuances', source='compensation_benefits', dest='role_nuances')\n",
    "machine.add_transition(trigger='summarize', source='role_nuances', dest='final_summary')\n",
    "\n",
    "# Example of using the state machine\n",
    "recruitment_assistant.ask_company_environment()\n",
    "print(recruitment_assistant.state)  # Output: company_environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Dynamic Question Generation with Decision Trees\n",
    "\n",
    "We use **Decision Trees** for dynamic questioning, where each node represents a question and each branch represents possible answers leading to different follow-up questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define sample training data for decision tree - features are hypothetical attributes, target is follow-up question ID\n",
    "X_sample = [[1, 0, 1], [0, 1, 1], [1, 1, 0], [0, 0, 1]]  # Example feature vectors\n",
    "y_sample = [0, 1, 2, 3]  # Follow-up question IDs\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_sample, y_sample)\n",
    "\n",
    "# Use decision tree to determine the next question\n",
    "sample_input = [1, 0, 1]\n",
    "next_question = decision_tree.predict([sample_input])\n",
    "print(f\"Next question ID: {next_question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Introducing Personalization and Rule-Based Logic\n",
    "\n",
    "We use **NLP models** for evaluating sentiment, determining the conversation tone, and dynamically adjusting questions to improve personalization.\n",
    "\n",
    "#### Step 8.1: Sentiment Analysis and Adaptive Questioning\n",
    "\n",
    "We use **Naïve Bayes** or **Logistic Regression** models for text classification to evaluate the sentiment of responses and determine the conversation's engagement level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train a simple sentiment model (example data)\n",
    "text_clf = ComplementNB()\n",
    "y_labels = np.abs(np.random.choice([0, 1], len(X_reduced)))  # Randomly generated labels for demonstration, ensure no negative values\n",
    "text_clf.fit(X_reduced, y_labels)\n",
    "\n",
    "# Analyze sentiment and adjust follow-up\n",
    "sample_response = \"I would prefer a remote work setting.\"\n",
    "sample_vector = vectorizer.transform([sample_response])\n",
    "sentiment = text_clf.predict(sample_vector)\n",
    "if sentiment == 1:\n",
    "    print(\"Positive sentiment detected, proceeding with follow-up questions about remote tools and flexibility.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8.2: Rule-Based Logic Stored in JSON\n",
    "\n",
    "To make the decision flow configurable and easier to maintain, we store the conversation rules in a JSON file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rules for conversation flow in a JSON format\n",
    "rules = {\n",
    "    \"role_requirements\": {\n",
    "        \"next\": \"company_environment\",\n",
    "        \"questions\": [\"What are the must-have skills for this role?\", \"Are there any certifications required?\"]\n",
    "    },\n",
    "    \"company_environment\": {\n",
    "        \"next\": \"compensation_benefits\",\n",
    "        \"questions\": [\"How many people are in the team?\", \"Can you describe the company culture?\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Example usage of JSON-based rules\n",
    "current_state = \"role_requirements\"\n",
    "for question in rules[current_state][\"questions\"]:\n",
    "    print(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Combining Predefined Question Templates and Dynamic Elements\n",
    "\n",
    "We blend **predefined question templates** with dynamically generated content to ensure the conversation is both personalized and comprehensive.\n",
    "\n",
    "- Start with a core set of questions (e.g., role-specific skills).\n",
    "- Adaptively generate follow-up prompts based on previous answers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of predefined question and dynamically generated follow-up\n",
    "core_questions = [\"What are the must-have skills for this role?\"]\n",
    "response = \"This role is temporary.\"\n",
    "\n",
    "# Use response to create a personalized follow-up\n",
    "if \"temporary\" in response.lower():\n",
    "    follow_up = \"Considering that the role is temporary, would you like to discuss the option for contract renewal and team integration procedures?\"\n",
    "    core_questions.append(follow_up)\n",
    "\n",
    "for question in core_questions:\n",
    "    print(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Splitting Data for Training and Evaluation\n",
    "\n",
    "We split our dataset into training and testing sets to evaluate our model's performance accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, gsearch_jobs['title'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Model Training\n",
    "\n",
    "We use an **SGDClassifier**, a linear model with stochastic gradient descent learning, which is efficient for large datasets.\n",
    "\n",
    "- **Why SGD**: It works well with high-dimensional data and supports various loss functions suitable for classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train SGD Classifier\n",
    "model = SGDClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Display training progress\n",
    "print(\"Model training complete. Now proceeding to evaluation...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12: Model Evaluation, Sentiment, Interview Response Analysis, and Explainability\n",
    "\n",
    "#### Step 12.1: Sentiment and Interview Response Analysis\n",
    "\n",
    "We add **sentiment analysis** to understand the overall sentiment behind the 'pros' and 'cons' sections, and the candidate interview responses. This helps gauge candidates' attitudes and alignment with company culture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Sentiment analysis for pros and cons\n",
    "gsearch_jobs['pros_sentiment'] = gsearch_jobs['description_tokens'].apply(lambda x: analyzer.polarity_scores(str(x))['compound'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12.2: Enhanced Analysis\n",
    "\n",
    "We use various metrics to assess content quality and coverage, ensuring that the model-generated questions align with the hiring requirements and cover essential job aspects.\n",
    "\n",
    "### Step 13: Explainability with SHAP\n",
    "\n",
    "We use **SHAP (SHapley Additive exPlanations)** to explain the output of our model, providing transparency in decision-making and helping us understand which features are most influential in predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a small subset of the training data to fit the SHAP explainer\n",
    "explainer = shap.Explainer(model, X_train[:100])\n",
    "shap_values = explainer(X_test[:10])\n",
    "\n",
    "# Plot summary of the SHAP values\n",
    "shap.summary_plot(shap_values, X_test[:10], feature_names=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 14: Combining Graph Database for Conversation Flexibility\n",
    "\n",
    "Using a **Graph Database** like Neo4j to store and navigate through your conversation flow provides flexibility to adapt questions based on user interaction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection to Neo4j database\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\"))\n",
    "\n",
    "# Define a function to add nodes and relationships\n",
    "def add_question(tx, question, answer_options):\n",
    "    tx.run(\"CREATE (q:Question {text: $question})\", question=question)\n",
    "    for option in answer_options:\n",
    "        tx.run(\"MATCH (q:Question {text: $question}) CREATE (q)-[:HAS_OPTION]->(:Option {text: $option})\", question=question, option=option)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
